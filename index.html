<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>We're Still Marching — Thembeka Prototype</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"/>

  <!-- A-Frame + AR.js -->
  <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.3.2/aframe/build/aframe-ar.min.js"></script>

  <style>
    html, body { margin:0; height:100%; }
    body { background:#000; color:#fff; font-family: Arial, sans-serif; }

    /* Keep camera video visible behind canvas (canvas ABOVE video) */
    video#arjs-video, video.arjs-video, video[playsinline] {
      position: fixed !important;
      top: 0; left: 0;
      width: 100% !important;
      height: 100% !important;
      object-fit: cover;
      z-index: 0;          /* below canvas */
      background: #000;
    }
    canvas.a-canvas, .a-canvas canvas {
      position: fixed !important;
      top: 0; left: 0;
      width: 100% !important;
      height: 100% !important;
      z-index: 1;          /* above video */
    }
    a-scene {
      position: fixed !important;
      top: 0; left: 0;
      width: 100% !important;
      height: 100% !important;
    }

    /* Start overlay to capture user gesture */
    #start-screen {
      position: fixed; inset: 0;
      display: flex; align-items: center; justify-content: center;
      background: rgba(0,0,0,0.85); z-index: 10; flex-direction: column;
      text-align: center; padding: 24px;
    }
    #start-screen h2 { margin: 0 0 8px; }
    #start-screen button {
      padding: 12px 22px; font-size: 18px;
      border-radius: 8px; border: none; background:#ff6b6b; color:#fff;
      cursor: pointer;
    }
    #hint { margin-top: 12px; font-size: 14px; color: #ddd; max-width: 360px; }
  </style>
</head>

<body>
  <!-- Tap gate so mobile browsers allow audio/video later -->
  <div id="start-screen">
    <h2>We're Still Marching — Prototype</h2>
    <button id="start-button">Start the Experience</button>
    <div id="hint">Tap “Start”, allow camera, then point your phone at a printed <b>HIRO</b> marker.</div>
  </div>

  <a-scene
    embedded
    vr-mode-ui="enabled: false"
    renderer="antialias:true; alpha:true; precision: mediump"
    arjs="sourceType: webcam; facingMode: environment; debugUIEnabled: false; detectionMode: mono; patternRatio: 0.9"
  >
    <a-assets>
      <!-- VIDEO TEXTURE (use MP4/H.264) -->
      <video id="thembekaVideo"
             src="assets/thembeka.mp4"
             preload="auto"
             playsinline
             webkit-playsinline
             crossorigin="anonymous"
             muted
             loop></video>

      <!-- Voiceover -->
      <audio id="thembekaAudio"
             src="assets/thembeka.mp3"
             preload="auto"
             playsinline
             webkit-playsinline></audio>
    </a-assets>

    <!-- Single marker -->
    <a-marker preset="hiro" id="marker-thembeka" emitevents="true">
      <!-- Show the video on this plane (flat = unlit so it’s never black) -->
      <a-plane id="videoPlane"
               position="0 0 0"
               rotation="-90 0 0"
               width="1" height="1"
               material="src: #thembekaVideo; shader: flat"
               visible="false"></a-plane>

      <!-- Optional: obvious debug shape to confirm tracking -->
      <a-torus-knot id="probe"
                    position="0 0.5 0"
                    radius="0.25" radius-tubular="0.06"
                    color="#FF00FF"
                    visible="false"></a-torus-knot>
    </a-marker>

    <a-entity camera></a-entity>
  </a-scene>

  <script>
    const startBtn     = document.querySelector('#start-button');
    const startScreen  = document.querySelector('#start-screen');
    const marker       = document.querySelector('#marker-thembeka');

    const vid          = document.querySelector('#thembekaVideo');
    const voice        = document.querySelector('#thembekaAudio');

    const plane        = document.querySelector('#videoPlane');
    const probe        = document.querySelector('#probe');

    // Prime media on user gesture (iOS requirement)
    startBtn.addEventListener('click', async () => {
      try {
        // Prime VIDEO: play then immediately pause to unlock with sound
        await vid.play();
        vid.pause();
        vid.currentTime = 0;
        vid.muted = false;   // unmute after the gesture
      } catch(e) {
        console.log('Video prime failed', e);
      }

      try {
        // Prime AUDIO similarly
        await voice.play();
        voice.pause();
        voice.currentTime = 0;
      } catch(e) {
        console.log('Audio prime failed', e);
      }

      startScreen.style.display = 'none';
    });

    // When marker is found, show and play
    marker.addEventListener('markerFound', async () => {
      if (plane) plane.setAttribute('visible', 'true');
      if (probe) probe.setAttribute('visible', 'true');

      try { await vid.play(); } catch(e){ console.log('Video play blocked', e); }
      try { await voice.play(); } catch(e){ console.log('Audio play blocked', e); }
    });

    // When marker is lost, hide and reset
    marker.addEventListener('markerLost', () => {
      if (plane) plane.setAttribute('visible', 'false');
      if (probe) probe.setAttribute('visible', 'false');

      vid.pause();    vid.currentTime = 0;
      voice.pause();  voice.currentTime = 0;
    });
  </script>

</body>
</html>
